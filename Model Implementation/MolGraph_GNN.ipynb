{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9703389-09f3-495f-b94a-01d6e0937860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.error')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9b691a-4d9b-4120-9c06-5bf5a2f6a1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>Y</th>\n",
       "      <th>Map</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB04571</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB00855</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>NCC(=O)CCC(O)=O</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB09536</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>O=[Ti]=O</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB01600</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB09000</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID1      ID2  Y                                                Map  \\\n",
       "0  DB04571  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "1  DB00855  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "2  DB09536  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "3  DB01600  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "4  DB09000  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "\n",
       "                                           X1  \\\n",
       "0         CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1   \n",
       "1                             NCC(=O)CCC(O)=O   \n",
       "2                                    O=[Ti]=O   \n",
       "3       CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1   \n",
       "4  CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N   \n",
       "\n",
       "                                                  X2  \n",
       "0  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  \n",
       "1  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  \n",
       "2  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  \n",
       "3  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  \n",
       "4  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddi_fp = 'drugbank.tab'\n",
    "ddi = pd.read_csv(ddi_fp, sep='\\t')\n",
    "ddi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4caf098b-3786-430e-a79c-62b4de7ecc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86]\n"
     ]
    }
   ],
   "source": [
    "print(ddi['Y'].dtype)\n",
    "print(ddi['Y'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9139efc-099c-4ae0-8237-f0355113126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddi size: 191808\n",
      "ddi_cleaned size: 191798\n",
      "Rows removed: 10\n"
     ]
    }
   ],
   "source": [
    "# filter incorrect smiles rows out \n",
    "\n",
    "def valid_smiles(smiles): \n",
    "    if not isinstance(smiles, str): \n",
    "        return False\n",
    "    return Chem.MolFromSmiles(smiles) is not None\n",
    "\n",
    "invalid_rows = ddi[~(ddi['X1'].apply(valid_smiles) & ddi['X2'].apply(valid_smiles))]\n",
    "ddi_cleaned = ddi.drop(invalid_rows.index).reset_index(drop = True)\n",
    "\n",
    "print(f\"ddi size: {ddi.shape[0]}\")\n",
    "print(f\"ddi_cleaned size: {ddi_cleaned.shape[0]}\")\n",
    "print(f\"Rows removed: {len(ddi) - len(ddi_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c5cdc4-52b6-44f1-a066-6cea9199535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {49: 0, 47: 1, 73: 2, 75: 3, 60: 4}\n",
      "Y\n",
      "0    10000\n",
      "1    10000\n",
      "2    10000\n",
      "3     9470\n",
      "4     8397\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17854/3903372731.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ddi_filt = ddi_filt.groupby('Y', group_keys=False).apply(lambda x: x.sample(min(len(x), n), replace=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "top5_labels = ddi_cleaned['Y'].value_counts().nlargest(5).index\n",
    "ddi_filt = ddi_cleaned[ddi_cleaned['Y'].isin(top5_labels)].reset_index(drop = True)\n",
    "\n",
    "label_mapping = {label: idx for idx, label in enumerate(top5_labels)}\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "ddi_filt['Y'] = ddi_filt['Y'].map(label_mapping)\n",
    "\n",
    "n = 10000  # Number of samples per label\n",
    "#ddi_filt = ddi_filt.groupby('Y', group_keys=False).apply(lambda x: x.sample(n, replace=True)).reset_index(drop=True)\n",
    "ddi_filt = ddi_filt.groupby('Y', group_keys=False).apply(lambda x: x.sample(min(len(x), n), replace=False)).reset_index(drop=True)\n",
    "\n",
    "print(ddi_filt['Y'].value_counts())  # Check how many samples per label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394f0df9-c101-4d5d-bd2f-9e7a7db1b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert smiles string to graph\n",
    "def smiles_to_graph(smiles): \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if mol is None: \n",
    "        raise ValueError(f\"invalid SMILES string {smiles}\")\n",
    "\n",
    "    node_features = []\n",
    "    for atom in mol.GetAtoms(): \n",
    "        atomic_num = atom.GetAtomicNum()\n",
    "        degree = atom.GetDegree()\n",
    "        hybridization = atom.GetHybridization()\n",
    "        is_aromatic = atom.GetIsAromatic()\n",
    "        \n",
    "        features = [atomic_num, degree, int(hybridization), int(is_aromatic)]\n",
    "        node_features.append(features)\n",
    "        \n",
    "    edges = []\n",
    "    if mol.GetNumBonds() > 0 : \n",
    "        for bond in mol.GetBonds(): \n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edges.append((i, j))\n",
    "            edges.append((j, i))\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype = torch.long).t().contiguous() if edges else torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    x = torch.tensor(node_features, dtype = torch.float)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "def convert_to_graphs(ddi_filt): \n",
    "    graph_data = []\n",
    "    for _, row in ddi_filt.iterrows(): \n",
    "        graph_X1 = smiles_to_graph(row['X1'])\n",
    "        graph_X2 = smiles_to_graph(row['X2'])\n",
    "\n",
    "        graph_data.append((graph_X1, graph_X2, row['Y']))\n",
    "\n",
    "    return graph_data\n",
    "\n",
    "# convert codes to graphs\n",
    "graph_data = convert_to_graphs(ddi_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c374321-3edd-47b3-9603-a63359a58ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Data(x=[19, 4], edge_index=[2, 40]), Data(x=[26, 4], edge_index=[2, 56]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(graph_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76210223-a6d1-42f4-bb36-8130617562af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class DDI_GraphDataset(Dataset): \n",
    "    def __init__(self, graph_data): \n",
    "        self.graph_data = graph_data\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.graph_data)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        graph_X1, graph_X2, label = self.graph_data[idx]\n",
    "        return graph_X1, graph_X2, torch.tensor(label, dtype = torch.long)\n",
    "    \n",
    "dataset = DDI_GraphDataset(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b2162e2-ef44-4b52-b6bc-c5c566de5891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[19, 4], edge_index=[2, 40]),\n",
       " Data(x=[26, 4], edge_index=[2, 56]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2fe67e4-3243-4201-9fb8-daba33732194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    X1_batch, X2_batch, labels = zip(*batch)\n",
    "    \n",
    "    X1_batch = Batch.from_data_list(X1_batch)\n",
    "    X2_batch = Batch.from_data_list(X2_batch)\n",
    "    \n",
    "    labels = torch.stack(labels)\n",
    "    \n",
    "    return X1_batch, X2_batch, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3326c31-d1c5-4bf7-bc33-5764c7d0ceb9",
   "metadata": {},
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4967e59-b84e-4fa8-ac0b-f7b99e8763cf",
   "metadata": {},
   "source": [
    "for graph_X1_batch, graph_X2_batch, labels in loader:\n",
    "    # Forward pass through the GNN\n",
    "    z1 = gnn(graph_X1_batch)\n",
    "    z2 = gnn(graph_X2_batch)\n",
    "    \n",
    "    # Combine embeddings\n",
    "    z_combined = torch.cat([z1, z2, torch.abs(z1 - z2), z1 * z2], dim=1)\n",
    "    \n",
    "    # Forward pass through the classifier\n",
    "    output = classifier(z_combined)\n",
    "    \n",
    "    # Calculate loss and backpropagate\n",
    "    loss = criterion(output, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "362b4152-8917-4233-8fe2-f231cf51331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c9e1e99-b5f6-490b-83de-0da19b437f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = DDI_GraphDataset(graph_data)\n",
    "\n",
    "labels = [label for _, _, label in dataset]\n",
    "train_indices, test_indices = train_test_split(\n",
    "np.arange(len(dataset)), \n",
    "test_size = 0.2, \n",
    "stratify = labels, \n",
    "random_state = 42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "#loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "647db7e0-0fb8-4cff-8f51-72d5ef0eb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "gnn = GNN(in_channels = 4, hidden_dim = 8, out_dim = 5)\n",
    "classifier = nn.Linear(20, 5)  # Adjust the input size based on your GNN output\n",
    "optimizer = optim.Adam(list(gnn.parameters()) + list(classifier.parameters()), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08d1ed9f-5b42-4fdd-a327-e424cd8e5e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.562505841255188\n",
      "Epoch 2, Loss: 1.580553650856018\n",
      "Epoch 3, Loss: 1.5074833631515503\n",
      "Epoch 4, Loss: 1.5265101194381714\n",
      "Epoch 5, Loss: 1.5521981716156006\n",
      "Epoch 6, Loss: 1.5246347188949585\n",
      "Epoch 7, Loss: 1.7109894752502441\n",
      "Epoch 8, Loss: 1.512468695640564\n",
      "Epoch 9, Loss: 1.4684982299804688\n",
      "Epoch 10, Loss: 1.5067403316497803\n",
      "Epoch 11, Loss: 1.5810078382492065\n",
      "Epoch 12, Loss: 1.4927995204925537\n",
      "Epoch 13, Loss: 1.4266656637191772\n",
      "Epoch 14, Loss: 1.3921960592269897\n",
      "Epoch 15, Loss: 1.427808165550232\n",
      "Epoch 16, Loss: 1.613053798675537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.13      0.18      8000\n",
      "           1       0.30      0.47      0.37      8000\n",
      "           2       0.34      0.27      0.30      8000\n",
      "           3       0.41      0.41      0.41      7576\n",
      "           4       0.36      0.47      0.41      6717\n",
      "\n",
      "    accuracy                           0.35     38293\n",
      "   macro avg       0.35      0.35      0.33     38293\n",
      "weighted avg       0.35      0.35      0.33     38293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# training loop \n",
    "num_epochs = 16  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    gnn.train() \n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for graph_X1_batch, graph_X2_batch, labels in train_loader:\n",
    "        # forward pass through the GNN\n",
    "        z1 = gnn(graph_X1_batch)\n",
    "        z2 = gnn(graph_X2_batch)\n",
    "\n",
    "        # combine the graph embeddings\n",
    "        z_combined = torch.cat([z1, z2, torch.abs(z1 - z2), z1 * z2], dim=1)\n",
    "\n",
    "        # forward pass through the classifier\n",
    "        output = classifier(z_combined)\n",
    "\n",
    "        # calculate loss and backpropagate\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "    \n",
    "print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc925c38-dbcf-4689-8123-11022c7fe72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8476295471191406\n",
      "Epoch 2, Loss: 1.8380569219589233\n",
      "Epoch 3, Loss: 1.8323599100112915\n",
      "Epoch 4, Loss: 1.8289803266525269\n",
      "Epoch 5, Loss: 1.8243392705917358\n",
      "Epoch 6, Loss: 1.820809006690979\n",
      "Epoch 7, Loss: 1.8155337572097778\n",
      "Epoch 8, Loss: 1.8137401342391968\n",
      "Epoch 9, Loss: 1.812421441078186\n",
      "Epoch 10, Loss: 1.810024380683899\n",
      "Epoch 11, Loss: 1.808811068534851\n",
      "Epoch 12, Loss: 1.8067926168441772\n",
      "Epoch 13, Loss: 1.8044925928115845\n",
      "Epoch 14, Loss: 1.8039122819900513\n",
      "Epoch 15, Loss: 1.8017951250076294\n",
      "Epoch 16, Loss: 1.800451397895813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.14      0.19      2000\n",
      "           1       0.31      0.47      0.38      2000\n",
      "           2       0.33      0.27      0.30      2000\n",
      "           3       0.43      0.44      0.44      1894\n",
      "           4       0.38      0.48      0.42      1680\n",
      "\n",
      "    accuracy                           0.35      9574\n",
      "   macro avg       0.35      0.36      0.34      9574\n",
      "weighted avg       0.35      0.35      0.34      9574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_epochs = 16  \n",
    "\n",
    "# test loop \n",
    "for epoch in range(num_epochs):\n",
    "    gnn.eval() \n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for graph_X1_batch, graph_X2_batch, labels in test_loader:\n",
    "        # Forward pass through the GNN\n",
    "        z1 = gnn(graph_X1_batch)\n",
    "        z2 = gnn(graph_X2_batch)\n",
    "\n",
    "        # Combine the graph embeddings\n",
    "        z_combined = torch.cat([z1, z2, torch.abs(z1 - z2), z1 * z2], dim=1)\n",
    "\n",
    "        # Forward pass through the classifier\n",
    "        output = classifier(z_combined)\n",
    "\n",
    "        # Calculate loss and backpropagate\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "    \n",
    "print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec7192-406a-4e4d-89f1-d59aee473693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
