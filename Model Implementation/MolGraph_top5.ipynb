{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcba5dc4-dc2e-468b-bd15-9bbf0034fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rdkit\n",
    "#pip install torch-geometric\n",
    "\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.error')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65803b45-affd-4971-9c31-39a6c63875c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>Y</th>\n",
       "      <th>Map</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB04571</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB00855</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>NCC(=O)CCC(O)=O</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB09536</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>O=[Ti]=O</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB01600</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB09000</td>\n",
       "      <td>DB00460</td>\n",
       "      <td>1</td>\n",
       "      <td>#Drug1 may increase the photosensitizing activ...</td>\n",
       "      <td>CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N</td>\n",
       "      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID1      ID2  Y                                                Map  \\\n",
       "0  DB04571  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "1  DB00855  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "2  DB09536  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "3  DB01600  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "4  DB09000  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n",
       "\n",
       "                                           X1  \\\n",
       "0         CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1   \n",
       "1                             NCC(=O)CCC(O)=O   \n",
       "2                                    O=[Ti]=O   \n",
       "3       CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1   \n",
       "4  CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N   \n",
       "\n",
       "                                                  X2  \n",
       "0  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  \n",
       "1  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  \n",
       "2  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  \n",
       "3  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  \n",
       "4  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddi_fp = 'drugbank.tab'\n",
    "ddi = pd.read_csv(ddi_fp, sep='\\t')\n",
    "ddi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20e0330-fa03-4b3e-8c87-c2c71d6c28ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddi size: 191808\n",
      "ddi_cleaned size: 191798\n",
      "Rows removed: 10\n"
     ]
    }
   ],
   "source": [
    "# filter incorrect smiles rows out \n",
    "\n",
    "def valid_smiles(smiles): \n",
    "    if not isinstance(smiles, str): \n",
    "        return False\n",
    "    return Chem.MolFromSmiles(smiles) is not None\n",
    "\n",
    "invalid_rows = ddi[~(ddi['X1'].apply(valid_smiles) & ddi['X2'].apply(valid_smiles))]\n",
    "ddi_cleaned = ddi.drop(invalid_rows.index).reset_index(drop = True)\n",
    "\n",
    "print(f\"ddi size: {ddi.shape[0]}\")\n",
    "print(f\"ddi_cleaned size: {ddi_cleaned.shape[0]}\")\n",
    "print(f\"Rows removed: {len(ddi) - len(ddi_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28cda2a3-b5aa-41cd-8616-d6ca2f8b13b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {49: 0, 47: 1, 73: 2, 75: 3, 60: 4}\n",
      "Y\n",
      "0    10000\n",
      "1    10000\n",
      "2    10000\n",
      "3    10000\n",
      "4    10000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20019/1849153468.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ddi_filt = ddi_filt.groupby('Y', group_keys=False).apply(lambda x: x.sample(n, replace=True)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "top5_labels = ddi_cleaned['Y'].value_counts().nlargest(5).index\n",
    "ddi_filt = ddi_cleaned[ddi_cleaned['Y'].isin(top5_labels)].reset_index(drop = True)\n",
    "\n",
    "label_mapping = {label: idx for idx, label in enumerate(top5_labels)}\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "ddi_filt['Y'] = ddi_filt['Y'].map(label_mapping)\n",
    "\n",
    "#ddi_filt = ddi_cleaned.iloc[:1000].reset_index(drop=True)\n",
    "#ddi_filt = ddi_filt.iloc[:20000].reset_index(drop=True)\n",
    "#print(\"Unique mapped labels:\", ddi_filt['Y'].unique())\n",
    "#print(ddi_filt.shape[0])\n",
    "\n",
    "n = 10000  # Number of samples per label\n",
    "#ddi_filt = ddi_filt.groupby('Y', group_keys=False).apply(lambda x: x.sample(n, replace=True)).reset_index(drop=True)\n",
    "ddi_filt = ddi_filt.groupby('Y', group_keys=False).apply(lambda x: x.sample(min(len(x), n), replace=False)).reset_index(drop=True)\n",
    "\n",
    "print(ddi_filt['Y'].value_counts())  # Check how many samples per label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e916a6-3c6d-48eb-9b59-15f68fc86eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert smiles string to graph\n",
    "def smiles_to_graph(smiles): \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if mol is None: \n",
    "        raise ValueError(f\"invalid SMILES string {smiles}\")\n",
    "\n",
    "    node_features = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
    "\n",
    "    edges = []\n",
    "    if mol.GetNumBonds() > 0 : \n",
    "        for bond in mol.GetBonds(): \n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edges.append((i, j))\n",
    "            edges.append((j, i))\n",
    "    # else: \n",
    "    #     print(f\"No bonds found for molecule: {smiles}\")\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype = torch.long).t().contiguous() if edges else torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    x = torch.tensor(node_features, dtype = torch.float).view(-1, 1)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "def convert_to_graphs(ddi_filt): \n",
    "    graph_data = []\n",
    "    for _, row in ddi_filt.iterrows(): \n",
    "        graph_X1 = smiles_to_graph(row['X1'])\n",
    "        graph_X2 = smiles_to_graph(row['X2'])\n",
    "\n",
    "        graph_data.append((graph_X1, graph_X2, row['Y']))\n",
    "\n",
    "    return graph_data\n",
    "\n",
    "# convert codes to graphs\n",
    "graph_data = convert_to_graphs(ddi_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c56255-9d3d-475e-863e-12cb56b8fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GraphDataset(Dataset): \n",
    "    def __init__(self, graph_data): \n",
    "        self.graph_data = graph_data\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.graph_data)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        graph_X1, graph_X2, label = self.graph_data[idx]\n",
    "        return graph_X1, graph_X2, label\n",
    "\n",
    "# graph_dataset = GraphDataset(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14e7a205-ccf4-4867-a507-92e38c7721c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GNN \n",
    "\n",
    "\n",
    "class GNNModel(nn.Module): \n",
    "    def __init__(self, in_channels, hidden_channels, out_channels): \n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # concatenating X1 and X2\n",
    "        self.fc = nn.Linear(2 * hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data1, data2): \n",
    "        x1, edge_index1 = data1.x, data1.edge_index\n",
    "        x2, edge_index2 = data2.x, data2.edge_index\n",
    "\n",
    "        # apply graph convolution on graph 1 (X1)\n",
    "        x1 = F.relu(self.conv1(x1, edge_index1))\n",
    "        x1 = self.conv2(x1, edge_index1)\n",
    "    \n",
    "        # apply graph convolution on graph 2 (X2)\n",
    "        x2 = F.relu(self.conv1(x2, edge_index2))\n",
    "        x2 = self.conv2(x2, edge_index2)\n",
    "    \n",
    "        x = torch.cat([x1.mean(dim=0), x2.mean(dim=0)], dim = -1)\n",
    "        # output layer predicts one of 20 classes\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dd3b593-6abb-4e9d-98cf-b984537d433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import random \n",
    "\n",
    "def gnn_function(epochs, hidden_channels): \n",
    "\n",
    "    graph_dataset = GraphDataset(graph_data)\n",
    "\n",
    "    labels = []\n",
    "    for i in graph_dataset: \n",
    "        labels.append(i[2])\n",
    "    \n",
    "    train_data, test_data = train_test_split(graph_dataset.graph_data, test_size = 0.2, stratify = labels, random_state = 42)\n",
    "    train_dataset = GraphDataset(train_data)\n",
    "    test_dataset = GraphDataset(test_data)\n",
    "    \n",
    "    # define model, loss func, and optimizer\n",
    "    model = GNNModel(in_channels=1, hidden_channels = hidden_channels, out_channels=20)\n",
    "    optimizer = Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    \n",
    "    # training \n",
    "    for epoch in range(epochs):  \n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for data1, data2, label in train_dataset:\n",
    "            label = torch.tensor(label, dtype = torch.long)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data1, data2)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data1, data2, label in test_dataset:\n",
    "            output = model(data1, data2)\n",
    "            \n",
    "            predicted = output.argmax(dim = -1)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            y_pred.append(predicted)\n",
    "            y_true.append(label)\n",
    "            \n",
    "            if isinstance(label, torch.Tensor): \n",
    "                total += label.size(0)\n",
    "            else: \n",
    "                total += 1\n",
    "    \n",
    "    accuracy = correct/total * 100\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division = 0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    print(f'Accuracy: {accuracy} %')\n",
    "    print(f'Precision Score: {precision}')\n",
    "    print(f'Recall Score: {recall}')\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# print(f'Accuracy: {accuracy} %')\n",
    "# print(f'Precision Score: {precision}')\n",
    "# print(f'Recall Score: {recall}')\n",
    "\n",
    "\n",
    "    # Print the loss for the current epoch\n",
    "    # print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1c532-84c3-4909-b35d-3a77271da540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_hyps(epochs, hidden_channels): \n",
    "\n",
    "    # initialize first model\n",
    "    best_epochs = 0 \n",
    "    best_hidden_channels = 0\n",
    "    iteration = 0\n",
    "    best_acc = gnn_function(epochs[0], hidden_channels[0])\n",
    "    grid = pd.DataFrame(columns = epochs, index = hidden_channels)\n",
    "\n",
    "    for e in range(0, len(epochs)): \n",
    "        for h in range(0, len(hidden_channels)): \n",
    "            iteration += 1\n",
    "            print(f'Epochs: {epochs[e]}, Hidden Channels : {hidden_channels[h]}')\n",
    "            acc = gnn_function(epochs[e], hidden_channels[h])\n",
    "    \n",
    "            grid.iloc[h, e] = acc\n",
    "            if acc >= best_acc: \n",
    "                best_acc = acc\n",
    "                best_epochs = epochs[e]\n",
    "                best_hidden_channels = hidden_channels[h]\n",
    "    \n",
    "    print(f\"Optimal hyperparameters: {best_epochs} epochs, {best_hidden_channels} hidden channels\")\n",
    "    return grid\n",
    "\n",
    "epochs = [5, 7]\n",
    "hidden_channels = [8]\n",
    "\n",
    "# function call \n",
    "opt_hyps(epochs, hidden_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "442e5f4b-363f-482a-ad54-2472e5828247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.0 %\n",
      "Precision Score: 0.04\n",
      "Recall Score: 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10,000 samples with replacement \n",
    "\n",
    "gnn_function(5, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3119430-3dd4-4651-be1d-8a8529f3ce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.29 %\n",
      "Precision Score: 0.15031254674286987\n",
      "Recall Score: 0.2029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.29"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10,000 samples max, no replacement\n",
    "\n",
    "gnn_function(5, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a1294-0e57-458e-8e5f-86dd2b5119ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
